#Get Argument
args = (commandArgs(trailingOnly = TRUE))
if (length(args) == 1){
  RpackagesDir = args[1]
} else {
  cat('usage: Rscript summaryanalysis.R <RpackagesDir>\n')
}

.libPaths(new=c(RpackagesDir, .libPaths()))

#Library Needed
library(tidyverse)
library(stringr)
library(dplyr)
library(ggplot2)
library(stringr)
library(tsibble)
library(feasts)
library(lubridate)


#HISTORICAL DATA
historical_data = read.csv("results/dailydata.csv")
historical_data = historical_data %>% 
  mutate(date = as.Date(date)) %>% 
  arrange(exchange, date) 

# Calculating slopes per exchange
historical_data = historical_data %>%
  group_by(exchange) %>%
  mutate(slope = signif(as.double(coef(lm(market_daily ~ date))[2]), 3)) %>%
  ungroup()

# Creating the tsibble for features
historical_data_ts = as_tsibble(historical_data, index = date, key = exchange)

# Calculating trend features for each exchange
historical_trends = historical_data_ts %>%
  group_by(exchange) %>%
  features(market_daily, features = feature_set(tags = "trend")) %>%
  ungroup() %>%
  select(exchange, trend_strength, spikiness, linearity, curvature) %>%
  mutate(
    trend_strength = signif(trend_strength, 3), 
    linearity = signif(linearity, 3), 
    curvature = signif(curvature, 3), 
    spikiness = signif(spikiness, 3)
  )

# Joining trend features with the original data
historical_data = historical_data %>%
  left_join(historical_trends, by = "exchange") %>% mutate(historical_data %>% mutate(norm_slope = slope/market_daily))

#grouped historical data
grouped_historical_data = historical_data %>% group_by(exchange) %>% summarise(market_daily = mean(market_daily), slope = mean(slope), trend_strength = mean(trend_strength), spikiness = mean(spikiness)) %>% mutate(norm_slope = slope/market_daily)

mean_hist_slope = mean(grouped_historical_data$norm_slope)
sd_hist_slope = sd(grouped_historical_data$norm_slope)

grouped_historical_data = grouped_historical_data %>% mutate(z_slope = (norm_slope - mean_hist_slope)/sd_hist_slope, score = -11.86 + -22.741*z_slope + 14.859*trend_strength + 35489*spikiness + 24.067*z_slope*trend_strength)





#SIMULATED DATA
simulated_data = read.csv("results/montecarlo.csv")
simulated_data = simulated_data %>% 
  mutate(date = as.Date(date)) %>% 
  arrange(exchange, date)  





# Set initial parameters, can adjust based on travel budget, vacation duration, number of simulations, number of exchanges, etc...
amount_money = 10000
travel_duration = 123 # days
num_exchanges_options = 1:5


perform_simulation <- function(num_exchanges, currency_pair) {
  specific_data <- simulated_data %>% filter(exchange == currency_pair)
  results <- c()  # Store results of each simulation
  
  if (nrow(specific_data) == 0) {
    warning(paste("No data found for currency pair:", currency_pair))
    return(NA)
  }
  
  # Define the full period for exchanges
  full_period <- as.Date(max(specific_data$date)) - as.Date(min(specific_data$date))
  # Initialize money in base and foreign currencies
  base_currency_amount <- amount_money
  foreign_currency_amount <- 0
  
  for (exchange_index in 1:num_exchanges) {
    # Calculate the time of the next exchange
    if (exchange_index == 1) {
      exchange_date <- as.Date(min(specific_data$date))
    } else {
      exchange_date <- exchange_date + floor(full_period / num_exchanges)
    }
    
    # Find the closest rate up to the exchange date
    rate_on_date <- specific_data %>%
      filter(date <= exchange_date) %>%
      summarize(closest_rate = last(market_daily)) %>%
      pull(closest_rate)
    
    # Convert a portion of base currency at the sampled rate
    exchange_amount <- base_currency_amount / (num_exchanges - exchange_index + 1)
    converted_amount <- exchange_amount * rate_on_date
    base_currency_amount <- base_currency_amount - exchange_amount
    foreign_currency_amount <- foreign_currency_amount + converted_amount
  }
  
  # Final result is all foreign currency plus any remaining base currency
  total_after_all_exchanges <- foreign_currency_amount + base_currency_amount
  results = total_after_all_exchanges

  
  # Average result over all simulations
  #return(mean(results, na.rm = TRUE))
  return(results)
}

perform_simulation(1,"AUD/JPY")

currency_pairs = unique(simulated_data$exchange)

# Initialize the matrix to hold simulation outcomes for each currency pair
simulation_outcomes = matrix(nrow = length(num_exchanges_options), ncol = length(currency_pairs))
colnames(simulation_outcomes) = currency_pairs
rownames(simulation_outcomes) = paste(num_exchanges_options, "exchanges")

# Perform simulations for each currency pair and number of exchanges
for (currency_pair in currency_pairs) {
  for (num_exchanges in num_exchanges_options) {
    simulation_outcomes[num_exchanges, currency_pair] = perform_simulation(num_exchanges, currency_pair)
  }
}

# Matrix to DF 
simulation_results_df = as.data.frame(simulation_outcomes)

print(simulation_results_df)










#My work to find the coefficients - deleted when we publish
# Initialize an empty list to store row indices of maximum values for each column
max_row_indices <- c()

# Loop through each column
for (col_index in seq_along(simulation_results_df)) {
  # Find row index of maximum value in the current column
  max_row_index <- which.max(simulation_results_df[[col_index]])
  
  # Add row index to the list with column name as key
  max_row_indices[[colnames(simulation_results_df)[col_index]]] <- max_row_index
}

print(max_row_indices)

test_data = read.csv("results/dailydata.csv")
test_data = test_data %>% 
  mutate(date = as.Date(date)) %>% 
  arrange(exchange, date) 
test_data = test_data %>%
  group_by(exchange) %>%
  mutate(slope = signif(as.double(coef(lm(market_daily ~ date))[2]), 3)) %>% ungroup()

test_data = test_data %>%
  left_join(historical_trends, by = "exchange")

sum_test_data = test_data %>% group_by(exchange) %>% summarise(market_daily = mean(market_daily), slope = mean(slope), trend_strength = mean(trend_strength), spikiness = mean(spikiness))

sum_test_data = sum_test_data %>% mutate(norm_slope = slope/market_daily)



sum_test_data$indice = max_row_indices

mean_slope = mean(sum_test_data$norm_slope)
sd_slope = sd(sum_test_data$norm_slope)


sum_test_data = sum_test_data %>% mutate(indice = as.numeric(indice),z_slope = (norm_slope - mean_slope)/sd_slope, score = -11.86 + -22.741*z_slope + 14.859*trend_strength + 35489*spikiness + 24.067*z_slope*trend_strength, prediction = ifelse((score > 3 & indice >= 3) | (score < 3 & indice <= 3), "correct", "wrong"))
sum(sum_test_data$prediction == "correct")


test_lm = lm(data = sum_test_data, indice ~ z_slope:trend_strength + z_slope + trend_strength + spikiness)
summary(test_lm)
